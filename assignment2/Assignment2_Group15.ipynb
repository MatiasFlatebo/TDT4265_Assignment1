{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - TDT4265 - Group 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "<img src=\"task1a.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "<img src=\"task1b.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2a)\n",
    "\n",
    "- The mean value for X_train was: 33.55274553571429\n",
    "- The Standard deviation for X_train was: 78.87550070784701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2c)\n",
    "\n",
    "<img src=\"task2c_train_loss.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2d)\n",
    "\n",
    "\n",
    "- The number of parameters were calculated in the get_number_of_params() function in task2.py\n",
    "\n",
    "- The number of params with 784 input layer, 64 hidden layer and 10 output layer was 50890 (Have added for bias term here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is our plot with the different combinations of \"techinique\" to improve the model. The tricks of the trade!\n",
    "\n",
    "<img src=\"task3d_accuracies_with_diff_tricks.png\">\n",
    "\n",
    "\n",
    "- Max accuracy for scenario Original 0.8945\n",
    "    - Orginal base line model\n",
    "- Max accuracy for scenario Improved Sigmoid 0.877\n",
    "    - Improved sigmoid activation function, which shows in increase in learning speed, but falls off in accuracy over time\n",
    "- Max accuracy for scenario Improved Weight Init 0.9523\n",
    "    - We see that this are a large improvement both in learning speed and accuracy. There also seem to take a long time before the model overfits and the early stopping kicks in.\n",
    "- Max accuracy for scenario With Momentum 0.9196\n",
    "    - Same as for the improved weight init, but seems to be a bit slower in learning speed and overfits faster with less accuracy\n",
    "- Max accuracy for scenario All Improvements 0.9607\n",
    "    - This is the best model, with all the improvements combined. It has the best learning speed and accuracy, and converges fast to a good solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "\n",
    "Here is the similar plot from task 3, but now the number of hidden units changed from 64 to 32\n",
    "\n",
    "<img src=\"task4a_accuracies_with_diff_tricks.png\">\n",
    "\n",
    "- Max accuracy for scenario Original 0.8895\n",
    "- Max accuracy for scenario Improved Sigmoid 0.8811\n",
    "- Max accuracy for scenario Improved Weight Init 0.9396\n",
    "- Max accuracy for scenario With Momentum 0.9118\n",
    "- Max accuracy for scenario All Improvements 0.9432\n",
    "\n",
    "We observe that the accuracy is lower for all the scenarios. The performance is worse. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "\n",
    "Here is the similar plot from task 3, but now the number of hidden units changed from 64 to 128\n",
    "\n",
    "\n",
    "<img src=\"task4b_accuracies_with_diff_tricks.png\">\n",
    "\n",
    "\n",
    "- Max accuracy for scenario Original 0.901\n",
    "- Max accuracy for scenario Improved Sigmoid 0.8748\n",
    "- Max accuracy for scenario Improved Weight Init 0.9572\n",
    "- Max accuracy for scenario With Momentum 0.9213\n",
    "- Max accuracy for scenario All Improvements 0.9679\n",
    "\n",
    "\n",
    "\n",
    "We observe that the accuracy is a bit higher for all the scenarios compared to the 64 hidden units. \n",
    "Compared to the 32 hidden units, the accuracy is a lot higher for all the scenarios.\n",
    "\n",
    "This is not what we expected based on the task, but the difference is not too much. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4d)\n",
    "\n",
    "\n",
    "For this task, we observed by trial and fail that two hidden layers of 59 units is about the same number of parameters as a single hidden layer of 64 units. \n",
    "\n",
    "- The number of params, as stated earlier, with a single 64 units hidden layer is 50890.\n",
    "- The new number of params with two hidden layers of 59 units is 50455.\n",
    "\n",
    "<img src=\"task4d_loss_with_diff_tricks.png\">\n",
    "\n",
    "<img src=\"task4d_accuracies_with_diff_tricks.png\">\n",
    "\n",
    "We also observed that the two hidden layers of 59 units had a higher accuracy than the single hidden layer of 64 units.\n",
    "\n",
    "- Max accuracy for scenario with all tricks of the trade is 0.9626\n",
    "    - This is slighly higher again, which means the two hidden layers are slighly better on the classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4e)\n",
    "\n",
    "\n",
    "This task we take a look at the training loss of a 10 hidden layer network with 64 units in each layer. We are comparing this to the baseline model with all \"tricks of the trade\" applied. \n",
    "\n",
    "<img src=\"task4e_loss_with_diff_tricks.png\">\n",
    "\n",
    "\n",
    "- Min Loss for scenario all Improvements 2.4165162806958054\n",
    "- Min Loss for scenario all Improvements 2.4034787796197197\n",
    "\n",
    "We see that the loss of the deep model increases significantly compared to the baseline model. This is due to the vanishing gradient problem. The deep model is not able to learn as well as the baseline model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
